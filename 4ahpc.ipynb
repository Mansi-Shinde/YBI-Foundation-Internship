{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjRTl1KkH/s8NUpzm4peLc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mansi-Shinde/YBI-Foundation-Internship/blob/master/4ahpc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4a - vector addition\n"
      ],
      "metadata": {
        "id": "ZZBEgvcUDE_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mkDieeEDAtG",
        "outputId": "2c9fdac4-5aae-4dde-d739-1cdc07d485ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nvcc is typically associated with NVIDIA's CUDA compiler, which is used for compiling CUDA code. To check the version of nvcc installed on your system, you can open a terminal or command prompt and run the nvcc --version command yourself. This will display the version information of the CUDA compiler installed on your machine."
      ],
      "metadata": {
        "id": "pPzIR8Dlxy_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2_7uyveDZ5v",
        "outputId": "7f23717e-ed4c-458d-ea50-709ccf25f3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-b3z6utpv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-b3z6utpv\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=09bc6e6cc7a56000ad4587dfe600310fc408b2a8ba8519eeeade3771e967f9a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oxfxio33/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9rBwtixDpBs",
        "outputId": "753cd579-7fee-462d-9a86-2a601b1f6f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the nvcc_plugin extension in Jupyter Notebook,"
      ],
      "metadata": {
        "id": "c3l9V0ffyJ49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code you provided is an example of vector addition using CUDA in C++. It demonstrates how to perform element-wise addition of two arrays on a GPU using parallel threads and blocks.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "The vectorAddition kernel function is defined. It takes three integer pointers x, y, and z as arguments. These pointers represent the input arrays a and b, and the output array c. Each thread calculates the sum of corresponding elements from x and y arrays and stores the result in the z array. It also prints the calculation for each thread.\n",
        "\n",
        "In the main function, two input arrays a and b are defined, along with an output array c.\n",
        "\n",
        "Pointers d, e, and f are declared to be used for memory allocation on the GPU.\n",
        "\n",
        "The cudaMalloc function is called to allocate memory on the GPU for arrays d, e, and f.\n",
        "\n",
        "The cudaMemcpy function is used to copy the contents of arrays a and b from the CPU to the GPU memory allocated for d and e respectively.\n",
        "\n",
        "The vectorAddition kernel is launched with 2 blocks and 3 threads per block using the <<< >>> syntax. The d, e, and f pointers are passed as arguments.\n",
        "\n",
        "After the kernel execution, the result array c is copied back from the GPU memory to the CPU memory using cudaMemcpy.\n",
        "\n",
        "The c array is printed to display the sum of the two input arrays.\n",
        "\n",
        "The allocated GPU memory is freed using cudaFree.\n",
        "\n",
        "The program terminates.\n",
        "\n",
        "Note that in order to run CUDA code in Jupyter Notebook, you need to have a compatible NVIDIA GPU and the CUDA toolkit installed and properly configured. Additionally, you need to load the nvcc_plugin extension as mentioned earlier."
      ],
      "metadata": {
        "id": "wEnEdJKhyUTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "__global__ void vectorAddition(int *x,int *y, int *z)\n",
        "{\n",
        "    int id=blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \n",
        "    /* blockIdx.x gives the respective block id which starts from 0 */\n",
        "    /* threadIdx.x gives the respective thread id which starts from 0 */\n",
        "    /* blockDim.x gives the dimension of block i.e. number of threads in one block */\n",
        " \n",
        "    z[id]=x[id]+y[id]; \n",
        "    printf(\"Thread %d and Block %d : %d + %d = %d\\n\", threadIdx.x, blockIdx.x, x[id], y[id], z[id] );\n",
        "}\n",
        "int main()\n",
        "{\n",
        "    int a[6] = {10, 20, 45, 32, 10, 21};\n",
        "    int b[6] = {5, 6, 3, 51, 44, 10};\n",
        "    int c[6];\n",
        "    int *d,*e,*f;\n",
        "    int i;\n",
        "    /* printf(\"\\n Enter six elements of first array\\n\");\n",
        "     for(i=0;i<6;i++)\n",
        "     {\n",
        "         scanf(\"%d\",&a[i]);\n",
        "     }\n",
        "     printf(\"\\n Enter six elements of second array\\n\");\n",
        "         for(i=0;i<6;i++)\n",
        "         {\n",
        "             scanf(\"%d\",&b[i]);\n",
        "         }\n",
        "    */\n",
        " \n",
        "  /* cudaMalloc() allocates memory from Global memory on GPU */\n",
        "    cudaMalloc((void **)&d,6*sizeof(int));\n",
        "    cudaMalloc((void **)&e,6*sizeof(int));\n",
        "    cudaMalloc((void **)&f,6*sizeof(int));\n",
        " \n",
        "\n",
        " /* cudaMemcpy() copies the contents from destination to source. Here destination is GPU(d,e) and source is CPU(a,b) */\n",
        " cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "/* call to kernel. Here 2 is number of blocks, 3 is the number of threads per block and d,e,f are the arguments */ \n",
        "    vectorAddition<<<2,3>>>(d,e,f);\n",
        " \n",
        " cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    printf(\"\\nSum of two arrays:\\n \");\n",
        "    for(i=0;i<6;i++)\n",
        "    {\n",
        "        printf(\"%d\\t\",c[i]);\n",
        "    }\n",
        "    cudaFree(d);\n",
        "    cudaFree(e);\n",
        "    cudaFree(f);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ZVoe_pDvrU",
        "outputId": "eba82569-a329-457d-b900-470314feb32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 and Block 0 : 10 + 5 = 15\n",
            "Thread 1 and Block 0 : 20 + 6 = 26\n",
            "Thread 2 and Block 0 : 45 + 3 = 48\n",
            "Thread 0 and Block 1 : 32 + 51 = 83\n",
            "Thread 1 and Block 1 : 10 + 44 = 54\n",
            "Thread 2 and Block 1 : 21 + 10 = 31\n",
            "\n",
            "Sum of two arrays:\n",
            " 15\t26\t48\t83\t54\t31\t\n"
          ]
        }
      ]
    }
  ]
}